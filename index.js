// 1. Import document loaders for different file formats

// 2. Import OpenAI language model and other related modules

// 3. Import Tiktoken for token counting

// 4. Import dotenv for loading environment variables and fs for file system operations

// 5. Initialize the document loader with supported file formats

// 6. Load documents from the specified directory

// 7. Define a function to calculate the cost of tokenizing the documents

// 8. Define a function to normalize the content of the documents

// 9. Define the main function to run the entire process

// 10. Calculate the cost of tokenizing the documents

// 11. Check if the cost is within the acceptable limit

// 12. Initialize the OpenAI language model

// 13. Check if an existing vector store is available

// 14. Load the existing vector store

// 15. Create a new vector store if one does not exist

// 16. Generate the vector store from the documents

// 17. Save the vector store to the specified path

// 18. Create a retrieval chain using the language model and vector store

// 19. Query the retrieval chain with the specified question

// 20. If the cost exceeds the limit, skip the embedding process

// 21. Run the main function
